# -*- coding: utf-8 -*-
"""Car_Price_Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UZrMnVrZoMHxsLmBHAupUt_2joiViQ_g

Importing Libraries
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import pickle

from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
from sklearn.ensemble import RandomForestRegressor

"""Loading the dataset"""

from google.colab import drive
drive.mount('/content/drive')

car = pd.read_csv('/content/drive/MyDrive/DSA_ICT/Data/car_prediction_data.csv')

"""EDA CHECK"""

car.head()

car.shape

car.columns

car.info()

#Check missing values
car.isnull().sum()

"""EDA GRAPHS"""

#Selling Price Distribution

plt.figure(figsize=(6,4))
sns.histplot(car['Selling_Price'], kde=True)
plt.title("Selling Price Distribution")
plt.show()

#Year vs Selling Price

plt.figure(figsize=(6,4))
sns.scatterplot(x='Year', y='Selling_Price', data=car)
plt.title("Year vs Selling Price")
plt.show()

#Kms Driven vs Selling Price

plt.figure(figsize=(6,4))
sns.scatterplot(x='Kms_Driven', y='Selling_Price', data=car)
plt.title("Kms Driven vs Selling Price")
plt.show()

"""FEATURE ENGINEERING"""

#Creating car age

from datetime import datetime

current_year = datetime.now().year
car['Car_Age'] = current_year - car['Year']

car.head()

#Removing Year column and keeping car_age

car.drop('Year', axis=1, inplace=True)
car.head()

#Droping the car name. it has too many unique values and it doesnt decide the price

car.drop('Car_Name', axis=1, inplace=True)
car.head()

"""One-Hot Encoding"""

car = pd.get_dummies(car, drop_first=True)
car.head()

#fix the boolean

car = car.astype(int)
car.head()

#Convert prices back to float

car['Selling_Price'] = car['Selling_Price'].astype(float)
car['Present_Price'] = car['Present_Price'].astype(float)

"""Trainâ€“Test Split"""

X = car.drop('Selling_Price', axis=1)
y = car['Selling_Price']

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.2,
    random_state=42
)

print("X_train shape:", X_train.shape)
print("X_test shape:", X_test.shape)

"""Feature Scaling using StandardScaler"""

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()

X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

X_train_scaled.shape, X_test_scaled.shape

"""Training Machine Learning Model"""

#Linear Regression

lr_model = LinearRegression()
lr_model.fit(X_train_scaled, y_train)

y_pred_lr = lr_model.predict(X_test_scaled)

print("R2 Score:", r2_score(y_test, y_pred_lr))
print("MAE:", mean_absolute_error(y_test, y_pred_lr))
print("RMSE:", np.sqrt(mean_squared_error(y_test, y_pred_lr)))

#Random Forest Regressor

rf_model = RandomForestRegressor(
    n_estimators=200,
    random_state=42
)

rf_model.fit(X_train_scaled, y_train)

y_pred_rf = rf_model.predict(X_test_scaled)

print("Random Forest R2:", r2_score(y_test, y_pred_rf))
print("Random Forest MAE:", mean_absolute_error(y_test, y_pred_rf))
print("Random Forest RMSE:", np.sqrt(mean_squared_error(y_test, y_pred_rf)))

"""FINAL DECISION - Random Forest is the final model"""

#Save Model & Scaler

pickle.dump(rf_model, open('car_price_model.pkl', 'wb'))
pickle.dump(scaler, open('scaler.pkl', 'wb'))